{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamgarai98/UCL_MSc_Project/blob/main/Dataset_Creation_Analysis/Dataset_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create dataframes of data and store as csv files in a folder"
      ],
      "metadata": {
        "id": "c52rkzWgWqbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Set script location to own development space\n",
        "#MY_DEVELOPMENT_SPACE = '/content/drive/MyDrive/development/adam/'\n",
        "#os.chdir(MY_DEVELOPMENT_SPACE)"
      ],
      "metadata": {
        "id": "OIAhIrMaGPa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41cbe1b-28b4-499e-c58c-0b67fc2d6c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "/content/drive/MyDrive/development/adam\n",
            " dataframes\t\t     lateral_model_1    requirements.txt\n",
            " Dataset_Analysis.ipynb      Lateral_TF.ipynb\n",
            "\"Dataset's_Creation.ipynb\"   Old_Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports NOT CLEAN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import glob\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import load_img\n",
        "from keras.utils import img_to_array\n",
        "from keras import applications\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqW7gQSEU5TW",
        "outputId": "a3786f43-827e-4f72-8277-f095d9ddd57f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy version: 1.22.4\n",
            "Tensorflow version: 2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8344789"
      },
      "outputs": [],
      "source": [
        "# Image paths\n",
        "project_dir = \"/content/drive/MyDrive/\"\n",
        "image_data_path = project_dir + 'ALICE_data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create lateral and dorsal dataframes from image folder\n",
        "\n",
        "Dataframes have the following as columns: Path to image, target and angle (lateral or dorsal)"
      ],
      "metadata": {
        "id": "ST92uk0tli7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets=list()\n",
        "full_paths=list()\n",
        "angle=list()"
      ],
      "metadata": {
        "id": "RlWjfHn-U55q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lebia Veridis = Ground Beetle\n",
        "#TODO Re-do with better loop and if else\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ALICE_data/Lebia viridis\"\n",
        "FILE_NAMES=os.listdir(IMAGE_FOLDER_PATH)\n",
        "\n",
        "for file_name in FILE_NAMES:\n",
        "  full_path = os.path.abspath(IMAGE_FOLDER_PATH+os.sep+file_name)\n",
        "  full_paths.append(full_path)\n",
        "  targets.append(\"Lebia viridis\")\n",
        "  if (\"lateral\" not in file_name):\n",
        "      angle.append(\"Dorsal\")\n",
        "  else:\n",
        "      angle.append(\"Lateral\")"
      ],
      "metadata": {
        "id": "T_XKoexVVBqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ephemera vulgata = mayfly\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ALICE_data/Ephemera vulgata\"\n",
        "FILE_NAMES=os.listdir(IMAGE_FOLDER_PATH)\n",
        "\n",
        "for file_name in FILE_NAMES:\n",
        "  full_path = os.path.abspath(IMAGE_FOLDER_PATH+os.sep+file_name)\n",
        "  full_paths.append(full_path)\n",
        "  targets.append(\"Ephemera vulgata\")\n",
        "  if (\"lateral\" not in file_name):\n",
        "      angle.append(\"Dorsal\")\n",
        "  else:\n",
        "      angle.append(\"Lateral\")"
      ],
      "metadata": {
        "id": "pbWSis4AVF1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leuctra fusca = stonefly\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ALICE_data/Leuctra fusca\"\n",
        "FILE_NAMES=(os.listdir(IMAGE_FOLDER_PATH))\n",
        "\n",
        "for file_name in FILE_NAMES:\n",
        "  full_path = os.path.abspath(IMAGE_FOLDER_PATH+os.sep+file_name)\n",
        "  full_paths.append(full_path)\n",
        "  targets.append(\"Leuctra fusca\")\n",
        "  if (\"lateral\" not in file_name):\n",
        "      angle.append(\"Dorsal\")\n",
        "  else:\n",
        "      angle.append(\"Lateral\")"
      ],
      "metadata": {
        "id": "nJAlpaz1VGAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Limnephilus nigriceps = caddisfly\n",
        "IMAGE_FOLDER_PATH = \"/content/drive/MyDrive/ALICE_data/Limnephilus nigriceps\"\n",
        "FILE_NAMES=(os.listdir(IMAGE_FOLDER_PATH))\n",
        "for file_name in FILE_NAMES:\n",
        "  full_path = os.path.abspath(IMAGE_FOLDER_PATH+os.sep+file_name)\n",
        "  full_paths.append(full_path)\n",
        "  targets.append(\"Limnephilus nigriceps\")\n",
        "  if (\"lateral\" not in file_name):\n",
        "      angle.append(\"Dorsal\")\n",
        "  else:\n",
        "      angle.append(\"Lateral\")"
      ],
      "metadata": {
        "id": "HRVWsPS-VGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make whole dataframe\n",
        "dataset=pd.DataFrame()\n",
        "dataset['image_path']=full_paths\n",
        "dataset['target']=targets\n",
        "dataset[\"angle\"]=angle"
      ],
      "metadata": {
        "id": "yjCNiCHgVGYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataframe into dorsal and lateral views\n",
        "dorsalDF = dataset[dataset['angle'] == \"Dorsal\"]\n",
        "dorsalDF = dorsalDF.reset_index(drop=True)\n",
        "\n",
        "lateralDF = dataset[dataset['angle'] == \"Lateral\"]\n",
        "lateralDF = lateralDF.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fSyA7dZ2WGkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now do a 60/20/20 training/test/validation split on each dataset\n",
        "\n",
        "**### Note: since every specimen has both a lateral and dorsal view and is in order in the original dataframe, both the lateral and dorsal dataframes will contain the same specimen in either the train, validation or test dataframe.**\n",
        "\n",
        "\n",
        "If a train test split is done on the original data somewhere else, then the random state (42) should be consistent to reproduce the same dataframes"
      ],
      "metadata": {
        "id": "IwJqXJJbmNHP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For lateral view\n",
        "# Create a 60/20/20 train/validation/test split\n",
        "\n",
        "trainDF_lat, validDF_lat = train_test_split(lateralDF,\n",
        "                                              test_size=0.2,\n",
        "                                              random_state=42,\n",
        "                                              shuffle=True\n",
        "                                             )\n",
        "\n",
        "trainDF_lat, testDF_lat = train_test_split(trainDF_lat,\n",
        "                                           test_size=0.25,\n",
        "                                           random_state=42,\n",
        "                                           shuffle=True\n",
        "                                          )"
      ],
      "metadata": {
        "id": "VuG9qgv-mozr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For dorsal view\n",
        "# Create a 60/20/20 train/validation/test split\n",
        "\n",
        "trainDF_dors, validDF_dors = train_test_split(dorsalDF,\n",
        "                                              test_size=0.2,\n",
        "                                              random_state=42,\n",
        "                                              shuffle=True\n",
        "                                             )\n",
        "\n",
        "trainDF_dors, testDF_dors = train_test_split(trainDF_dors,\n",
        "                                             test_size=0.25,\n",
        "                                             random_state=42,\n",
        "                                             shuffle=True\n",
        "                                            )"
      ],
      "metadata": {
        "id": "al37EuEfmoX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save datasets to google drive"
      ],
      "metadata": {
        "id": "CL3Hrht7mJVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, reset index column for each DF\n",
        "trainDF_lat = trainDF_lat.reset_index(drop=True)\n",
        "validDF_lat = validDF_lat.reset_index(drop=True)\n",
        "testDF_lat = testDF_lat.reset_index(drop=True)\n",
        "\n",
        "trainDF_dors = trainDF_dors.reset_index(drop=True)\n",
        "validDF_dors = validDF_dors.reset_index(drop=True)\n",
        "testDF_dors = testDF_dors.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "MLnYs-lky_LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert DF's to csv and save in the dataframes folder in my dev space\n",
        "dataset.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/dataset.csv', encoding = 'utf-8-sig')\n",
        "\n",
        "lateralDF.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/lateralDF.csv', encoding = 'utf-8-sig')\n",
        "dorsalDF.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/dorsalDF.csv', encoding = 'utf-8-sig')\n",
        "\n",
        "trainDF_lat.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/trainDF_lat.csv', encoding = 'utf-8-sig')\n",
        "validDF_lat.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/validDF_lat.csv', encoding = 'utf-8-sig')\n",
        "testDF_lat.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/testDF_lat.csv', encoding = 'utf-8-sig')\n",
        "\n",
        "trainDF_dors.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/trainDF_dors.csv', encoding = 'utf-8-sig')\n",
        "validDF_dors.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/validDF_dors.csv', encoding = 'utf-8-sig')\n",
        "testDF_dors.to_csv(MY_DEVELOPMENT_SPACE + 'dataframes/testDF_dors.csv', encoding = 'utf-8-sig')\n",
        "\n",
        "# To import run like this with argument index_col=0\n",
        "# dorsalDF=pd.read_csv('/content/drive/MyDrive/development/adam/dorsalDF.csv',index_col=0)"
      ],
      "metadata": {
        "id": "Y4YVe_WKx0i4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}